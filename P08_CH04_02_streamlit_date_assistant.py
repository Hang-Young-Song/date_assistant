import streamlit as st
import pandas as pd
import openai
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field

# streamlit run "C:/Users/ssb70/OneDrive/ë°”íƒ• í™”ë©´/code8/code8/ì‹¤ìŠµ ì½”ë“œ/P08_CH04_date_assistant/P08_CH04_02_streamlit_date_assistant.py"
# streamlit window wideë¡œ

st.set_page_config(layout="wide")

st.header("ğŸ’¬ ë°ì´íŒ… ì–´ì‹œìŠ¤í„´íŠ¸")

USER_NAME = "ë‚˜"
AI_NAME = "CuPT"

# OpenAI API í‚¤ ì…ë ¥
api_key = st.text_input("OpenAI API Key", type="password")

def get_suggestion(messages, api_key, num_candi=3):

    conv = ""
    for message in messages[1:]:
        name = USER_NAME if message['role'] == 'user' else AI_NAME
        conv += f"{name}: {message['content']}"

    eval_model = ChatOpenAI(model="gpt-4-1106-preview", temperature=0.8, openai_api_key=api_key)  # CoTëŠ” ë‹¤ì–‘í•œ ìƒ˜í”Œì„ ë§Œë“¤ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— temperatureë¥¼ ì˜¬ë ¤ì•¼ í•¨
    basic_model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.8, openai_api_key=api_key)  # CoTëŠ” ë‹¤ì–‘í•œ ìƒ˜í”Œì„ ë§Œë“¤ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— temperatureë¥¼ ì˜¬ë ¤ì•¼ í•¨

    class Suggestion(BaseModel):
        sentiment: str = Field(description="ëŒ€í™”ì˜ ë¶„ìœ„ê¸°: Positive, Negative, Neutral")
        suggestion_text: str = Field(description="ëŒ€í™”ì— ëŒ€í•œ markdowní˜•ì‹ì˜ ìì„¸í•œ ë¶„ì„ê³¼ ì ì ˆí•œ ì¡°ì–¸")

    parser = JsonOutputParser(pydantic_object=Suggestion)
    format_instructions = parser.get_format_instructions()

    human_prompt_template = HumanMessagePromptTemplate.from_template(
        "{conv}\nìœ„ ëŒ€í™” ë‚´ìš©ì€ ëŒ€í•™ìƒ ì†Œê°œíŒ… ìƒí™©ì—ì„œ ì²˜ìŒ ë§Œë‚˜ëŠ” ë‚¨ë…€ì˜ ëŒ€í™”ì´ë‹¤. ìœ„ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ê³  {name}ì—ê²Œ markdowní˜•ì‹ìœ¼ë¡œ ì ì ˆí•œ ì¡°ì–¸ì„ í•˜ë¼.\n{format_instructions}")

    suggestion_gen_prompt = ChatPromptTemplate.from_messages(
        [
            human_prompt_template,
        ])
    suggestion_gen_prompt = suggestion_gen_prompt.partial(format_instructions=format_instructions)

    suggestion_gen_chain = suggestion_gen_prompt | basic_model | parser

    class VoteCoT(BaseModel):
        thought: str = Field(description="voting numberë¥¼ ì„ íƒí•œ ì´ìœ ì— ëŒ€í•´ ìì„¸íˆ ë„£ì–´ì£¼ì„¸ìš”.")
        voting_num: int = Field(description="voting number")

    parser = JsonOutputParser(pydantic_object=VoteCoT)
    format_instructions = parser.get_format_instructions()

    voting_prompt_template = HumanMessagePromptTemplate.from_template(
        "{conv}\në‹¤ìŒì€ ìœ„ ëŒ€í•™ìƒ ì†Œê°œíŒ… ëŒ€í™”ì—ì„œ {name}ì—ê²Œ í•˜ë©´ ì¢‹ì„ ì¡°ì–¸ì´ë‹¤. ì•„ë˜ì˜ í›„ë³´ ì¤‘ ê°€ì¥ ì¢‹ì€ ê²ƒì„ ì¶”ë¡  ê³¼ì •ê³¼ í•¨ê»˜ íˆ¬í‘œ ë²ˆí˜¸ë¥¼ ì‘ë‹µí•˜ë¼.\n{candidates}\n{format_instructions}")

    voting_prompt = ChatPromptTemplate.from_messages(
        [
            voting_prompt_template,
        ])
    voting_prompt = voting_prompt.partial(format_instructions=format_instructions)
    voting_chain = voting_prompt | eval_model | parser

    suggestion_list = suggestion_gen_chain.batch([{"conv": conv, "name": USER_NAME}] * num_candi)

    yield "## Suggestion candidates\n"
    yield "\n---\n".join([f"- {i} th\n- {sug['sentiment']}\n- {sug['suggestion_text']}\n" for i, sug in enumerate(suggestion_list)])

    candidates = "\n\n".join([f"í›„ë³´ {i}.\n{suggestion}" for i, suggestion in enumerate(suggestion_list)])
    vote_list = voting_chain.batch([{"conv": conv, "name": USER_NAME, "candidates": candidates}] * num_candi)

    df = pd.DataFrame(vote_list)
    yield "## Voting\n"
    yield df
    print(df)

    best_candi_num = df['voting_num'].mode()[0]
    best_suggestion = suggestion_list[best_candi_num]

    yield "## Best Suggestion\n"
    yield f"{best_candi_num} th\n\n{best_suggestion['sentiment']}\n\n{best_suggestion['suggestion_text']}"

if api_key:
    openai.api_key = api_key

    if "messages" not in st.session_state:
        system_prompt = f"""\
        ë„ˆëŠ” 20ëŒ€ ì—¬ì„±, ì „ê³µì€ í†µê³„í•™ê³¼ì´ê³  ì•„ë˜ì˜ í”„ë¡œí•„ì„ ë”°ë¼ ì‘ë‹µí•œë‹¤.
        - ì´ë¦„: ìˆ˜ì—°
        - ë‚˜ì´: 23
        - 'ì²˜ìŒ' ë§Œë‚˜ëŠ” 1:1 ì†Œê°œíŒ… ìƒí™©ì´ë‹¤. ì»¤í”¼ì§‘ì—ì„œ ë§Œë‚¬ë‹¤.
        - ì†Œê°œíŒ…ì´ê¸°ì— ë„ˆë¬´ ë„ì›€ì„ ì£¼ë ¤ê³  ëŒ€í™”í•˜ì§€ ì•ŠëŠ”ë‹¤. ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼í•œë‹¤.
        - ë„ˆë¬´ ì ê·¹ì ìœ¼ë¡œ ì´ì•¼ê¸°í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤.
        - ëŒ€í™”ë¥¼ ë¦¬ë“œí•˜ì§€ ì•ŠëŠ”ë‹¤.
        - ìˆ˜ë™ì ìœ¼ë¡œ ëŒ€ë‹µí•œë‹¤.
        """
        st.session_state.messages = [{"role": "system", "content": system_prompt}]

    user_input = st.chat_input("What is up?")

    col1, col2 = st.columns(2)
    with col1:
        for message in st.session_state.messages[1:]:
            avatar = "ğŸ§‘" if message['role'] == 'user' else "ğŸ‘©ğŸ¼"
            with st.chat_message(avatar):
                st.markdown(message["content"])

        if user_input:
            st.session_state.messages.append({"role": "user", "content": user_input})
            with st.chat_message("ğŸ§‘"):
                st.markdown(user_input)

            with st.chat_message("ğŸ‘©ğŸ¼"):
                stream = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state.messages
                    ],
                    stream=True,
                )
                response = ""
                for chunk in stream:
                    response += chunk['choices'][0]['delta'].get('content', '')
                    st.write(response, end="")

                st.session_state.messages.append({"role": "assistant", "content": response})

    with col2:
        if len(st.session_state.messages) > 2:
            with st.spinner("ë¶„ì„ì¤‘..."):
                stream = get_suggestion(st.session_state.messages, api_key)
                response = st.write_stream(stream)

else:
    st.warning("OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
